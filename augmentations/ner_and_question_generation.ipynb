{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from pororo import Pororo\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dataset = load_from_disk('../data/train_dataset/train/')\n",
    "# valid_dataset = load_from_disk('../data/train_dataset/validation/')\n",
    "\n",
    "ner = Pororo(task=\"ner\", lang=\"ko\")\n",
    "\n",
    "# ner tags\n",
    "# PS\": \"PERSON\",\"LC\": \"LOCATION\",\"OG\": \"ORGANIZATION\",\"AF\": \"ARTIFACT\",\n",
    "# \"DT\": \"DATE\",\"TI\": \"TIME\",\"CV\": \"CIVILIZATION\",\"AM\": \"ANIMAL\",\n",
    "# \"PT\": \"PLANT\",\"QT\": \"QUANTITY\",\"FD\": \"STUDY_FIELD\",\n",
    "# \"TR\": \"THEORY\",\"EV\": \"EVENT\",\"MT\": \"MATERIAL\",\"TM\": \"TERM\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = train_dataset['context']\n",
    "print(len(contexts))\n",
    "contexts = list(set(contexts))\n",
    "print(len(contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_lists = []\n",
    "for i in tqdm(range(len(contexts))):\n",
    "    sample = ner(contexts[i])\n",
    "    ner_pairs = tuple(set(sample))\n",
    "#     print(f\"pairs len: {len(ner_pairs)}\")\n",
    "    ner_list = []\n",
    "    for k, v in sample:\n",
    "        if v != 'O' and k not in ner_list:\n",
    "            ner_list.append(k)\n",
    "#     print(f\"ner list len: {len(list(set(ner_list)))}\")\n",
    "    ner_lists.append(list(set(ner_list)))\n",
    "#     print(f\"total len: {len(ner_lists)}\")\n",
    "    \n",
    "print(len(ner_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(ner_lists) # 1450 인덱스부터 다시시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts[1450] = '호박 잎은 심장모양 또는 콩팥모양으로, 커다랗고 거친 털로 덮여 있으며 가장자리가 5개로 얕게 갈라지고 갈래조각에 톱니가 있다 잎자루가 길고, 어긋나기한다. 꽃은 암수한그루로서, 수꽃과 암꽃이 따로 핀다 6월부터 서리가 내릴 때까지 종 모양의 노란 꽃이 잎겨드랑이에 1개씩 달려 핀다 수꽃에만 있는 화분을 벌이 암꽃에 옮기면 수분이 되고, 수분된 암꽃에서 호박이 자란다 암꽃 하나하나가 단 하루만 피어 수분할 수 있는 데다가 호박꽃 대부분이 수꽃이기 때문에 실제로 호박을 생성하는 꽃은 몇 송이밖에 없다 수꽃은 꽃대가 길며 꽃받침통이 얕고 갈래조각의 기부가 꽃부리에 붙어 있으며 암꽃은 꽃대가 짧고 밑부분에 긴 씨방이 있으며 꽃받침갈래조각이 다소 잎같이 된다. 덩굴은 단면이 오각형이고 긴 흰색 솜털이 나있으며 덩굴손으로 감으면서 자라지만 개량된 것은 덩굴성이 아닌 것도 있다. 호박 열매는 여러 종류가 있으며, 모양과 빛깔도 품종에 따라 다르다 원형 또는 타원형으로 껍질이 단단하거나 무르다 속은 결이 거칠고 끈끈한 섬유질로 이루어져 있으며 열매 가운데에 씨가 들어 있다 열매의 무게는 대개 7-14kg 정도이지만 90kg이 넘게 나가는 것도 있다 열매는 대개 오렌지색을 띠며, 노란색·녹색·흰색 등 다른 색깔을 띠는 것도 많다 익으면 바깥면이 주로 짙은 황갈색을 띤다 편평하고 맛이 좋은 씨가 많이 들어 있다 완숙된 종자로 번식한다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(contexts[1450:]))):\n",
    "    sample = ner(contexts[i])\n",
    "    ner_pairs = tuple(set(sample))\n",
    "#     print(f\"pairs len: {len(ner_pairs)}\")\n",
    "    ner_list = []\n",
    "    for k, v in sample:\n",
    "        if v != 'O' and k not in ner_list:\n",
    "            ner_list.append(k)\n",
    "#     print(f\"ner list len: {len(list(set(ner_list)))}\")\n",
    "    ner_lists.append(list(set(ner_list)))\n",
    "#     print(f\"total len: {len(ner_lists)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ner_lists\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ner_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(ner_lists)):\n",
    "    count += len(ner_lists[i])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\\\n', ' ', text) # remove newline character\n",
    "    text = re.sub(r'\\s+', ' ', text) # remove continuous spaces\n",
    "    text = re.sub(r'#', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "preprocess_contexts = []\n",
    "for context in contexts:\n",
    "    preprocess_contexts.append(preprocess(context))\n",
    "    \n",
    "preprocess_ner_lists = []\n",
    "for i in range(len(ner_lists)):\n",
    "    preprocess_ner_list = []\n",
    "    for j in range(len(ner_lists[i])):\n",
    "        preprocess_ner_list.append(preprocess(ner_lists[i][j]))\n",
    "    preprocess_ner_lists.append(preprocess_ner_list)\n",
    "\n",
    "print(len(contexts), len(preprocess_contexts))\n",
    "print(len(ner_lists), len(preprocess_ner_lists))\n",
    "\n",
    "longer_preprocess_texts = []\n",
    "longer_preprocess_titles = []\n",
    "\n",
    "for i in tqdm(range(len(preprocess_contexts))):\n",
    "    for j in range(len(preprocess_ner_lists[i])):\n",
    "        longer_preprocess_texts.append(preprocess_contexts[i])\n",
    "        longer_preprocess_titles.append(preprocess_ner_lists[i][j])\n",
    "            \n",
    "longer_ner_df = pd.DataFrame(data={\"text\": longer_preprocess_texts, \"title\": longer_preprocess_titles})\n",
    "longer_ner_df.to_csv('preprocess_ner_dataset.csv')\n",
    "\n",
    "longer_ner_df\n",
    "\n",
    "preprocess_texts = []\n",
    "preprocess_titles = []\n",
    "\n",
    "for i in tqdm(range(len(preprocess_contexts))):\n",
    "    for j in range(len(preprocess_ner_lists[i])):\n",
    "        if len(preprocess_ner_lists[i][j]) == 1 and not re.sub(r'[가-힣]', '', preprocess_ner_lists[i][j]):\n",
    "            continue\n",
    "        else:\n",
    "            preprocess_texts.append(preprocess_contexts[i])\n",
    "            preprocess_titles.append(preprocess_ner_lists[i][j])\n",
    "\n",
    "ner_df = pd.DataFrame(data={\"text\": preprocess_texts, \"title\": preprocess_titles})\n",
    "ner_df.to_csv('preprocess_and_except_one_char_answer_ner_dataset.csv')\n",
    "\n",
    "print(count, len(preprocess_titles))\n",
    "# ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "c = pd.read_csv('/home/qa_generation/preprocess_and_except_one_char_answer_ner_dataset.csv')\n",
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pororo import Pororo\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "qg = Pororo(task=\"qg\", lang=\"ko\")\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "questions = []\n",
    "for i in tqdm(range(len(c))):\n",
    "    q = qg(\n",
    "        c['title'][i],\n",
    "        c['text'][i]\n",
    "    )\n",
    "    answers.append(c['title'][i])\n",
    "    contexts.append(c['text'][i])\n",
    "    questions.append(q)\n",
    "\n",
    "h = pd.DataFrame(data={\"context\": contexts, \"question\": questions, \"answer\": answers})\n",
    "# h = pd.DataFrame(data={\"question\": questions, \"answer\": answers})\n",
    "h.to_csv('ner_qgzz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pororo import Pororo\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "qg = Pororo(task=\"qg\", lang=\"ko\")\n",
    "\n",
    "n = qg(list(c['title']), list(c['text']))\n",
    "c['question'] = n\n",
    "c.to_csv('hoow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/wikipedia_documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "wiki['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki['18293']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts = [wiki[str(i)]['text'] for i in range(len(wiki))]\n",
    "# contexts = list(set(contexts))\n",
    "# len(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_dataset['document_id']\n",
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 not in idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_wiki = {}\n",
    "for i in range(len(wiki)):\n",
    "    if i not in idx:\n",
    "        ner_wiki[str(i)] = wiki[str(i)]\n",
    "len(ner_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_wiki['0']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = Pororo(task=\"pos\", lang=\"ko\")\n",
    "sts = Pororo(task=\"similarity\", lang=\"ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pppp = []\n",
    "# for k, v in ner(ner_wiki['0']['text']):\n",
    "#     if v != 'O':\n",
    "#         pppp.append((k, v))\n",
    "# list(set(pppp))\n",
    "\n",
    "ssss = []\n",
    "for i in range(len(pppp)):\n",
    "    ssss.append(sts(ner_wiki['0']['text'], pppp[i][0]))\n",
    "pppp[ssss.index(max(ssss))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_lists = []\n",
    "for i in tqdm(range(len(ner_wiki))):\n",
    "    sample = ner(ner_wiki[str(i)]['text'])\n",
    "    ner_pairs = tuple(set(sample))\n",
    "#     print(f\"pairs len: {len(ner_pairs)}\")\n",
    "    ner_list = []\n",
    "    for k, v in sample:\n",
    "        if v != 'O' and k not in ner_list:\n",
    "            ner_list.append((k, v))\n",
    "#     print(f\"ner list len: {len(list(set(ner_list)))}\")\n",
    "    ner_lists.append(list(set(ner_list)))\n",
    "#     print(f\"total len: {len(ner_lists)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
