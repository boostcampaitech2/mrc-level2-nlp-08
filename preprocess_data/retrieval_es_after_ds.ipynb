{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from datasets import load_from_disk, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from retrieval_model import BertEncoder\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, SequentialSampler)\n",
    "from tqdm import tqdm, trange\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/p_encoder\")\n",
    "q_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/q_encoder\")\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "if torch.cuda.is_available():\n",
    "        p_encoder.cuda()\n",
    "        q_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_doc(q_encoder, p_encoder, query, context, elastic_score_dict,k=100):\n",
    "    with torch.no_grad():\n",
    "        p_encoder.eval()\n",
    "        q_encoder.eval()\n",
    "\n",
    "        q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "        q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "\n",
    "        p_embs = []\n",
    "        # for p in context:\n",
    "        #     p = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "        #     p_emb = p_encoder(**p).to('cpu').numpy()\n",
    "        #     p_embs.append(p_emb)\n",
    "        p_seqs = tokenizer(context, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        dataset = TensorDataset(\n",
    "            p_seqs[\"input_ids\"],\n",
    "            p_seqs[\"attention_mask\"],\n",
    "            p_seqs[\"token_type_ids\"]\n",
    "        )\n",
    "        sampler = SequentialSampler(dataset)\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            sampler=sampler,\n",
    "            batch_size=100\n",
    "        )\n",
    "        for _, batch in enumerate(dataloader):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "            p_inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2]\n",
    "            }\n",
    "            \n",
    "            outputs = p_encoder(**p_inputs).to(\"cpu\").numpy()\n",
    "            p_embs.extend(outputs)\n",
    "\n",
    "    p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "    #print(p_embs.size())\n",
    "    dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "    #print(dot_prod_scores[0][0])\n",
    "    elastic_score = torch.Tensor([elastic_score_dict[query]])\n",
    "    #weight_score = weight * dot_prod_scores\n",
    "    #print(weight_score[0][0])\n",
    "    temp_score = elastic_score + dot_prod_scores\n",
    "    # print(dot_prod_scores)\n",
    "    # print(dot_prod_scores.size())\n",
    "    # print(temp_score)\n",
    "    \n",
    "    #rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "    rank = torch.argsort(temp_score, dim=1, descending=True).squeeze()\n",
    "    #print(rank)\n",
    "\n",
    "    return_context = []\n",
    "    for i in range(k):\n",
    "        return_context.append(context[rank[i]])\n",
    "    \n",
    "    return dot_prod_scores.squeeze(), return_context #,rank[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/elastic_new_valid_500.bin','rb') as f:\n",
    "    elastic_valid = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_new_valid_score_500.bin','rb') as f:\n",
    "    elastic_valid_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = list(elastic_valid.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [08:32<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "for i in tqdm(range(len(querys))):\n",
    "    _, re_rank = get_relevant_doc(q_encoder,p_encoder,querys[i],elastic_valid[querys[i]],elastic_valid_score)\n",
    "    hybrid[querys[i]] = re_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_valid_retrieval.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/elastic_new_train_500.bin','rb') as f:\n",
    "    elastic_train = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_new_train_score_500.bin','rb') as f:\n",
    "    elastic_train_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [2:20:41<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "querys = list(elastic_train.keys())\n",
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "for i in tqdm(range(len(querys))):\n",
    "    _, re_rank = get_relevant_doc(q_encoder,p_encoder,querys[i],elastic_train[querys[i]],elastic_train_score)\n",
    "    hybrid[querys[i]] = re_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_train_retrieval.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/elastic_retrieval_500.bin','rb') as f:\n",
    "    elastic_test = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_retrieval_score_500.bin','rb') as f:\n",
    "    elastic_test_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [21:26<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "querys = list(elastic_test.keys())\n",
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "for i in tqdm(range(len(querys))):\n",
    "    _, re_rank = get_relevant_doc(q_encoder,p_encoder,querys[i],elastic_test[querys[i]],elastic_test_score)\n",
    "    hybrid[querys[i]] = re_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_test_retrieval.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부피와 무게감을 나타낸 얼굴이나 짧은 목 등을 통해 알 수 있는 불상의 축조 시기는?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'경상북도 예천군 예천읍 동본동 3층석탑과 함께 전해오는 통일신라 후기의 불상으로 하나의 돌에 새겨진 전체 높이 3.46m의 거대한 석조불상이다. 머리에는 작은 소라 모양의 머리칼을 붙여 놓았으며, 정수리 부근에는 상투 모양의 머리(육계)가 큼직하게 표현되었다. 원만한 얼굴에는 길다란 눈, 짧은 코, 적당한 입이 적절하게 표현되어 부드러운 곡선의 얼굴과 함께 자비롭고 온화한 미소를 실감나게 나타내고 있다. 큰 얼굴에 비하여 작아진 상체는 굵고 짧은 목과 좁은 어깨, 짧은 팔 등이 평판적인 가슴과 함께 움츠린 듯하여 다소 위축된 느낌을 준다. 오른팔은 옆으로 내려 몸에 붙인 채 옷자락을 살짝 잡고 있으며, 왼손은 앞으로 들어 새끼 손가락을 제외한 손가락을 안으로 굽히고 있다. 양 어깨를 감싸고 입은 옷은 허벅지에서 Y자형으로 갈라지고 양 다리에서는 타원형의 주름을 만들면서 흐른다. 둔중하고 도식화된 이러한 형태의 옷주름 표현은 8세기 이후의 불상에서 흔히 볼 수 있는 모습으로 불상이 만들어진 연대를 짐작할 수 있게 해준다. 양 다리에서 있는 긴 타원형의 옷주름, 부피감 없는 둔중한 신체, 그러면서도 아직 경직화되지는 않은 얼굴 모습 등을 고려할 때 통일신라 불상양식을 계승하면서 고려시대로 넘어가는 과도기적인 작품으로 보인다.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 250\n",
    "print(querys[num])\n",
    "hybrid[querys[num]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
