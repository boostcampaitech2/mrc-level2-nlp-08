{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from datasets import load_from_disk, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from retrieval_model import BertEncoder\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, SequentialSampler)\n",
    "from tqdm import tqdm, trange\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/p_encoder\")\n",
    "q_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/q_encoder\")\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_doc(q_encoder, p_encoder, query, context, elastic_score_dict, k=100):\n",
    "    if torch.cuda.is_available():\n",
    "        p_encoder.cuda()\n",
    "        q_encoder.cuda()\n",
    "    with torch.no_grad():\n",
    "        p_encoder.eval()\n",
    "        q_encoder.eval()\n",
    "\n",
    "        q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "        q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "\n",
    "        p_embs = []\n",
    "        for p in context:\n",
    "            p = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "            p_emb = p_encoder(**p).to('cpu').numpy()\n",
    "            p_embs.append(p_emb)\n",
    "\n",
    "    p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "    dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "    elastic_score = torch.Tensor([elastic_score_dict[query]])\n",
    "    temp_score = elastic_score + dot_prod_scores\n",
    "    # print(dot_prod_scores)\n",
    "    # print(dot_prod_scores.size())\n",
    "    # print(temp_score)\n",
    "    \n",
    "    #rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "    rank = torch.argsort(temp_score, dim=1, descending=True).squeeze()\n",
    "\n",
    "    return_context = []\n",
    "    for i in range(k):\n",
    "        return_context.append(context[rank[i]])\n",
    "    \n",
    "    return dot_prod_scores.squeeze(), return_context #,rank[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/elastic_retrieval.bin','rb') as f:\n",
    "    elastic_valid = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_retrieval_score.bin','rb') as f:\n",
    "    elastic_valid_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = list(elastic_valid.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [18:22<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "hybrid = {}\n",
    "for i in tqdm(range(len(querys))):\n",
    "    _, re_rank = get_relevant_doc(q_encoder,p_encoder,querys[i],elastic_valid[querys[i]],elastic_valid_score)\n",
    "    hybrid[querys[i]] = re_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_retrieval_test.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유령'은 어느 행성에서 지구로 왔는가?\n",
      "영화를 시작할 때 해설자는 돌고래가 지구가 철거될 것을 알고 있었다고 설명한다. 돌고래는 사람들에게 뒤공중제비로 지구가 파괴될 것을 알렸지만, 사람들은 이를 잘못 이해하였고 결국 돌고래들은 안녕히, 그리고 물고기는 고마웠어요란 노래를 부르면서, 지구를 떠나게 된다. 그러던 어느 날, 불도저가 집으로 다가오는 소리를 들은 아서 덴트는 자기 집이 우회로를 건설하기 위해서 철거될 것이라는 것을 깨닫게 된다. 아서는 집의 철거를 막기 위해, 그의 집을 철거 하려는 불도저 앞에 드러눕게 된다. 아서의 시도는 그의 친구인 포드 프리펙트 때문에 방해를 받았고, 포드는 아서를 데리고 술집으로 가게 된다. 술집에서 포드는 자기가 길포드에서 온 것이 아니라, 외계인이란 걸 아서에게 말하였다. 포드는 아서가 그에게 보여준 친절(포드가 자동차를 지구를 지배하는 생물이라고 생각하고, 자동차와 악수하려고 할 때, 아서가 그를 길 밖으로 밀어내었다)로 보곤인이 초공간 고속도로를 놓기 위해 지구를 파괴하려는 순간 아서를 구하게 된다. 둘은 겨우 보곤 우주선에 히치하이킹을 하게 되고, 거기서 그들은 함장의 시(보곤의 시는 전우주에서 3번째로 최악이다)를 듣고 난 뒤, 우주로 던져지게 된다. 그들은 순수한 마음호에 의해서 구조되었는데, 순수한 마음호에는 이 우주선을 훔친 은하계 대통령 자포드 비블브락스와, 지금은 트릴리언이라 불리는 트리시아 맥밀런과, 우울증을 앓고 있는 안드로이드 마빈이 타고 있었다. 자포드는 순수한 마음호로 마그라테아에 가서 삶, 우주, 그리고 모든 것에 대한 답을 얻으려고 한다. 그들은 마그라테아로 진로를 돌렸으나, 순수한 마음호에 실린 무한 불가능 확률 추진기는 그들을 비트보들 6행성의 궤도에 올려놓는다. 비트보틀 6행성은 자트라바티드인들과 자포드와 대통령자리를 다투던 후마 카블라의 고향별이다. 후마 카블라는 마그라테아로 가는 좌표가 담겨있는 붉은 육면체를 가지고, 자포드에게 깊은 생각근처에 있는 모든 관점 총을 가져다 준다고 하면 좌표를 주겠다고 한다. 그리고 후마 카블라는 자포드가 총을 갖고 오도록 하기 위해 인질로 자포드의 다른 머리를 인질로 잡아둔다. 그들이 비트보틀 6행성에서 탈출할 때, 트릴리언은 그들의 본 행성인 보그스피어로 끌려가게 된다. 아서와 포드, 그리고 자포드는 트랄행성의 버그블래터 비스트에게 먹힐뻔한 트릴리언을 우여곡절 끝에 구하게 되고, 그들은 마그라테아로 향하게 된다. 마그라테아에서 자포드와 트릴리언 그리고 포드 프리펙트는 깊은 생각에게서 지구가 최호의 질문을 계산하는 컴퓨터였으며, 거기에 살고 있던 생명체들은 계산의 일부였다는 것을 알게 된다. 그들은 깊은 생각의 바로 밑에서 은하계의 화난 주부들의 회의에서 만들었고, 이 총을 맞은 사람은 이 총을 쏜 사람의 관점을 경험하게 되는 모든-관점 총을 찾게 된다. 아서는 슬라티바트패스트를 만나게 되고, 슬라티바트패스트는 아서에게 자신들이 지구를 만들었다고 설명하고, 또한 자신이 지구에 만든 피요르드 때문에 상을 탔다는 것을 말하였다. 그 뒤에 그는 아서와 함께 마그라테아의 행성 제작 공장으로 데리고 가게 된다. 마그라테아 행성 제작 공장에서, 아서는 지구의 백업본인 지구 마크 2를 보게 되었고 결국 그는 재창조된 영국의 자신의 집으로 들어가게 된다. 아서는 그의 집에 들어가서, 쥐들과 친구들을 다시 만나게 된다. 그가 자리에 앉고 난 뒤에, 쥐들은 질문의 한 부분을 구상하는 그의 뇌를 떼어내려고 하였다. 우여곡절끝에 아서는 쥐들의 속박에서 풀려나게 되고, 쥐들을 찻주전자로 짓눌러 버린다. 쥐포가 되머린 쥐들은, 깊은 생각의 제작자로 변하였다. 아서 일행이 집 밖에 나오니, 보곤인 부대가 아서의 집을 둘러싸고 있었고, 보곤 대대장은 그들을 죽이라는 명령을 내린다. 자포드는 아서의 우주선(사실 아서의 트레일러)을 조종해서 이 상황에서 탈출하려고 시도하지만 실패한다. 아서와 트릴리언은 모든-관점 총을 회수하려고 시도하였으나, 보곤 대대의 공격때문에 실패로 돌아가게 되었다. 그 총을 주우러 간 마빈은 보곤인의 공격을 맞고 쓰러졌고, 그들은 곧 죽을 것처럼 보였다. 그 때, 마빈이 그 총을 들어 보곤인들에게 모든-관점 총을 쏘았다. 그가 쏜 총으로 인해서 모든 보곤인들은 그의 관점을 느끼게 되었고, 그들은 모두 우울증에 빠지게 되었다. 보곤인의 공격이 분쇄되고, 지구의 모든 생명주기가 보곤인이 파괴하기 전으로 돌아가게 되었고, 아서와 그의 친구들은 순수한 마음호를 타고 우주저편의 레스토랑으로 다시 여행을 떠나게 되었다.\n",
      "\n",
      "목성의 대기에서 보이는 줄무늬는 적도와 평행하면서 행성을 둘러싸는 대(zone)와 띠(belt)라고 불리는 물질의 반대 순환류에 의한 것이다. 대는 밝은 줄무늬로, 대기에서 상대적으로 고도가 높은 곳에 있다. 이들은 내부의 상승 기류를 가지고 있는 고기압 영역이다. 띠는 어두운 줄무늬로, 대기에서 상대적으로 고도가 낮은 곳에 있으며, 내부의 하강 기류를 가진다. 이들은 저기압 영역이다. 이러한 구조는 지구 대기의 고기압 및 저기압 세포와 어느정도 유사하나, 국지 작은 기압 세포와 상반되는 행성 전체를 둘러싸는 위도 줄무늬로서 매우 다른 구조를 가지고 있다. 이는 행성의 빠른 자전과 근본적인 대칭으로 인한 결과로 보인다. 행성에는 국지적인 가열을 일으키는 바다나 육지가 없으며 자전 속도는 지구보다 훨씬 빠르다. 행성에는 서로 다른 크기와 색상을 갖는 점과 같은 작은 구조들이 있다. 목성에서, 그러한 특색 중에서 가장 유명한 것은 대적점으로, 적어도 300년 동안 존재해 왔다. 이러한 구조의 실체는 거대한 폭풍이다. 그러한 점 중에 일부는 적란운이기도 하다.\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(querys[idx])\n",
    "print(hybrid[querys[idx]][0])\n",
    "print()\n",
    "print(elastic_valid[querys[idx]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_valid[]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
