{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from datasets import load_from_disk, Dataset\n",
    "from transformers import AutoTokenizer,BertTokenizerFast\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from retrieval_model import BertEncoder,RobertaEncoder\n",
    "from torch import nn\n",
    "from torch.utils.data import (DataLoader,TensorDataset, SequentialSampler)\n",
    "from tqdm import tqdm, trange\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/p_encoder\")\n",
    "q_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/q_encoder\")\n",
    "#q_encoder_no = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/q_encoder\")\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
    "if torch.cuda.is_available():\n",
    "        p_encoder.cuda()\n",
    "        q_encoder.cuda()\n",
    "        #q_encoder_no.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wiki_context_id_pair.bin','rb') as f:\n",
    "    wiki_context_id = pickle.load(f)\n",
    "with open('/opt/ml/data/wiki_id_context_pair.bin','rb') as f:\n",
    "    wiki_id_context = pickle.load(f)\n",
    "# with open('/opt/ml/data/dense_embedding_add_title.bin','rb') as f:\n",
    "#     p_embs = pickle.load(f)\n",
    "with open('/opt/ml/data/dense_embedding.bin','rb') as f:\n",
    "    p_embs = pickle.load(f)\n",
    "with open('/opt/ml/data/sentence_transformer_valid_60613.pickle','rb') as f:\n",
    "    sen_tr = pickle.load(f)\n",
    "wiki_corpus = list(wiki_context_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    p_embs_cuda = torch.Tensor(p_embs).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_doc_with_embs(q_encoder, p_embs, query, elastic_ids, elastic_scores,sen_tr):\n",
    "    with torch.no_grad():\n",
    "        q_encoder.eval()\n",
    "        q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "        q_emb = q_encoder(**q_seqs_val).to('cuda')  #(num_query, emb_dim)\n",
    "\n",
    "\n",
    "    dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "    rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "    rank = rank.cpu().numpy().tolist()\n",
    "\n",
    "    es_id_score = {k:v for k,v in zip(elastic_ids,elastic_scores)}\n",
    "\n",
    "    elastic_top_n = len(set(elastic_ids)) # 중복된 ids가 있다.\n",
    "    hybrid_id_score = dict()\n",
    "    \n",
    "    sen_tr_id_score = dict()\n",
    "\n",
    "    for i in range(len(sen_tr)):\n",
    "        sen_tr_id_score[sen_tr[i]['corpus_id']] = sen_tr[i]['score']\n",
    "\n",
    "    for i in range(len(rank)):\n",
    "        dense_id = wiki_context_id[wiki_corpus[i]]\n",
    "\n",
    "        if dense_id in es_id_score:\n",
    "            lin_score = 1.1*dot_prod_scores[0][i].item() + es_id_score[dense_id]\n",
    "            hybrid_id_score[dense_id] =  sen_tr_id_score[dense_id]*10 + lin_score\n",
    "    \n",
    "    return hybrid_id_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:15<00:00, 15.55it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/data/elastic_valid_500.bin','rb') as f:\n",
    "    elastic_valid = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_valid_score_500.bin','rb') as f:\n",
    "    elastic_valid_score = pickle.load(f)\n",
    "querys = list(elastic_valid.keys())\n",
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "# querys[123]\n",
    "for i in tqdm(range(len(querys))):\n",
    "    q = querys[i]\n",
    "    context = []\n",
    "    #es,ds = get_relevant_doc_with_embs(q_encoder,p_embs_cuda,q,elastic_valid[q],elastic_valid_score)\n",
    "    hybrid_id_score = get_relevant_doc_with_embs(q_encoder,p_embs_cuda,q,elastic_valid[q],elastic_valid_score[q],sen_tr[q])\n",
    "    #hybrid_id_score = get_relevant_doc_with_embs(q_encoder,q_encoder_no,p_embs_cuda,p_embs_no_cuda,q,elastic_valid[q],elastic_valid_score[q])\n",
    "    hybrid_id_score = list(hybrid_id_score.items())\n",
    "    hybrid_id_score.sort(key = lambda x:x[1],reverse=True)\n",
    "    hybrid_ids = list(map(lambda x: x[0], hybrid_id_score))\n",
    "    hybrid[q] = hybrid_ids\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_valid_retrieval_500.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hybrid[querys[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [03:58<00:00, 16.58it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/data/elastic_train_1000.bin','rb') as f:\n",
    "    elastic_valid = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_train_score_1000.bin','rb') as f:\n",
    "    elastic_valid_score = pickle.load(f)\n",
    "querys = list(elastic_valid.keys())\n",
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "# querys[123]\n",
    "for i in tqdm(range(len(querys))):\n",
    "    q = querys[i]\n",
    "    context = []\n",
    "    #es,ds = get_relevant_doc_with_embs(q_encoder,p_embs_cuda,q,elastic_valid[q],elastic_valid_score)\n",
    "    hybrid_id_score = get_relevant_doc_with_embs(q_encoder,p_embs_cuda,q,elastic_valid[q],elastic_valid_score[q])\n",
    "    hybrid_id_score = list(hybrid_id_score.items())\n",
    "    hybrid_id_score.sort(key = lambda x:x[1],reverse=True)\n",
    "    hybrid_ids = list(map(lambda x: x[0], hybrid_id_score))\n",
    "    hybrid[q] = hybrid_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_train_retrieval_1000.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:39<00:00, 15.25it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/data/sentence_transformer_test_60613.pickle','rb') as f:\n",
    "    sen_tr = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_test_500.bin','rb') as f:\n",
    "    elastic_valid = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_test_score_500.bin','rb') as f:\n",
    "    elastic_valid_score = pickle.load(f)\n",
    "\n",
    "querys = list(elastic_valid.keys())\n",
    "\n",
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "# querys[123]\n",
    "for i in tqdm(range(len(querys))):\n",
    "    q = querys[i]\n",
    "    context = []\n",
    "    #es,ds = get_relevant_doc_with_embs(q_encoder,p_embs_cuda,q,elastic_valid[q],elastic_valid_score)\n",
    "    hybrid_id_score = get_relevant_doc_with_embs(q_encoder,p_embs_cuda,q,elastic_valid[q],elastic_valid_score[q],sen_tr[q])\n",
    "    hybrid_id_score = list(hybrid_id_score.items())\n",
    "    hybrid_id_score.sort(key = lambda x:x[1],reverse=True)\n",
    "    hybrid_ids = list(map(lambda x: x[0], hybrid_id_score))\n",
    "    hybrid[q] = hybrid_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_retrieval_st.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_doc_with_embs(q_encoder, p_embs, query, elastic_ids, elastic_scores):\n",
    "    with torch.no_grad():\n",
    "        q_encoder.eval()\n",
    "        q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "        q_emb = q_encoder(**q_seqs_val).to('cuda')  #(num_query, emb_dim)\n",
    "\n",
    "\n",
    "    dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "    rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "    rank = rank.cpu().numpy().tolist()\n",
    "\n",
    "    es_id_score = {k:v for k,v in zip(elastic_ids,elastic_scores)}\n",
    "\n",
    "    elastic_top_n = len(set(elastic_ids)) # 중복된 ids가 있다.\n",
    "    hybrid_id_score = dict()\n",
    "    \n",
    "\n",
    "    for i in range(len(rank)):\n",
    "        dense_id = wiki_context_id[wiki_corpus[i]]\n",
    "        #print(i, '-> ' ,dense_id)\n",
    "        #if dense_id in es_id_score:\n",
    "        if dense_id in es_id_score:\n",
    "\n",
    "            hybrid_id_score[dense_id] =   dot_prod_scores[0][i].item() + es_id_score[dense_id]\n",
    "    \n",
    "    return hybrid_id_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_retrieval_500.bin\", \"rb\") as file:\n",
    "    tt =  pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_retrieval_300.bin\", \"rb\") as file:\n",
    "    v6 =  pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = list(tt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제2캐나다기갑여단이 상륙한 곳은?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
