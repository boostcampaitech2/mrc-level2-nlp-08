{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, Dataset\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from retrieval_model import BertEncoder\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, SequentialSampler)\n",
    "from tqdm import tqdm, trange\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPR model load\n",
    "p_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/p_encoder\")\n",
    "q_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/q_encoder\")\n",
    "tokenizer =  AutoTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = load_from_disk(\"/opt/ml/data/train_dataset/train/\")\n",
    "#query_dataset = load_from_disk(\"../data/test_dataset/validation\") # test query\n",
    "#wiki_dataset = pd.read_json('../data/wikipedia_documents.json',orient='index') # wiki context\n",
    "#wiki_dataset = pd.read_csv('/opt/ml/data/preprocess_wiki_doc.csv')\n",
    "#train_dataset = load_from_disk(\"/opt/ml/data/train_dataset/new_validation/\")\n",
    "#origin_valid = load_from_disk(\"/opt/ml/data/train_dataset/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dataset = pd.read_csv('/opt/ml/data/preprocess_wiki_doc.csv')\n",
    "query_dataset = load_from_disk(\"/opt/ml/data/train_dataset/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 7\n",
    "# print(train_dataset['question'][num])\n",
    "# print(origin_valid['context'][num])\n",
    "# print('---------------')\n",
    "# print(train_dataset['context'][num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_corpus = list(set([example for example in train_dataset['context']]))\n",
    "wiki_corpus = list(set([example_wiki for example_wiki in wiki_dataset['text']]))\n",
    "query = query_dataset['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "55963\n"
     ]
    }
   ],
   "source": [
    "print(len(query))\n",
    "print(len(wiki_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1749/1749 [09:40<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_batch_size = 32\n",
    "def to_cuda(batch):\n",
    "  return tuple(t.cuda() for t in batch)\n",
    "if torch.cuda.is_available():\n",
    "    p_encoder.cuda()\n",
    "    q_encoder.cuda()\n",
    "\n",
    "# Construt dataloader\n",
    "train_p_seqs = tokenizer(wiki_corpus, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "valid_dataset = TensorDataset(\n",
    "    train_p_seqs[\"input_ids\"],\n",
    "    train_p_seqs[\"attention_mask\"],\n",
    "    train_p_seqs[\"token_type_ids\"]\n",
    ")\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler=valid_sampler,\n",
    "    batch_size=eval_batch_size\n",
    ")\n",
    "\n",
    "# Inference using the passage encoder to get dense embeddeings\n",
    "p_embs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "        valid_dataloader,\n",
    "        desc=\"Iteration\",\n",
    "        position=0,\n",
    "        leave=True\n",
    "    )\n",
    "    p_encoder.eval()\n",
    "\n",
    "    for _, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "        p_inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"token_type_ids\": batch[2]\n",
    "        }\n",
    "        \n",
    "        outputs = p_encoder(**p_inputs).to(\"cpu\").numpy()\n",
    "        p_embs.extend(outputs)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 8/8 [00:02<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_q_seqs = tokenizer(\n",
    "    query,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "query_dataset = TensorDataset(\n",
    "    train_q_seqs[\"input_ids\"],\n",
    "    train_q_seqs[\"attention_mask\"],\n",
    "    train_q_seqs[\"token_type_ids\"]\n",
    ")\n",
    "\n",
    "query_sampler = SequentialSampler(query_dataset)\n",
    "query_dataloader = DataLoader(\n",
    "    query_dataset,\n",
    "    sampler=query_sampler,\n",
    "    batch_size=eval_batch_size\n",
    ")\n",
    "\n",
    "q_embs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "        query_dataloader,\n",
    "        desc=\"Iteration\",\n",
    "        position=0,\n",
    "        leave=True\n",
    "    )\n",
    "    q_encoder.eval()\n",
    "\n",
    "    for _, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "        q_inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"token_type_ids\": batch[2]\n",
    "        }\n",
    "        \n",
    "        outputs = q_encoder(**q_inputs).to(\"cpu\").numpy()\n",
    "        q_embs.extend(outputs)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55963, 768)\n",
      "(240, 768)\n"
     ]
    }
   ],
   "source": [
    "p_embs = np.array(p_embs)\n",
    "q_embs = np.array(q_embs)\n",
    "\n",
    "print(p_embs.shape)\n",
    "print(q_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    p_embs_cuda = torch.Tensor(p_embs).to('cuda')\n",
    "    q_embs_cuda = torch.Tensor(q_embs).to('cuda')\n",
    "\n",
    "dot_prod_scores = torch.matmul(q_embs_cuda, torch.transpose(p_embs_cuda, 0, 1))\n",
    "rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 489.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dense_p_retrieval_result = {}\n",
    "idx = 0\n",
    "for i in tqdm(range(len(query))):\n",
    "    p_list = []\n",
    "    q = query[i]\n",
    "    for j in range(100):\n",
    "        p_list.append(wiki_corpus[rank[idx][j]])\n",
    "    dense_p_retrieval_result[q] = p_list\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/dense_valid_retrieval.bin\", \"wb\") as file:\n",
    "    pickle.dump(dense_p_retrieval_result,file)\n",
    "\n",
    "\n",
    "# dense_n_retrieval_result = {}\n",
    "# idx = 0\n",
    "# for i in tqdm(range(len(query))):\n",
    "#     p_list = []\n",
    "#     q = query[i]\n",
    "#     for j in range(10000,10004):\n",
    "#         p_list.append(wiki_corpus[rank[idx][j]])\n",
    "#     dense_n_retrieval_result[q] = p_list\n",
    "#     idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008년 소시에테 제네랄 은행의 선물딜러인 제롬 케르비엘에 의한 선물거래로 인해 49억 유로(71억 달러)의 손실이 발생하였다. 제롬은 은행 안에 비밀 사업체를 세우고 선물상품을 투자하다가 회사측에 71억 달러(한국돈으로 약 7조원)에 달하는 피해를 주었다. 이는 개인이 일으킨 금융사고로는 세계에서 가장 큰 규모의 사고로, 피해금액은 영국 베어링 은행을 외환파생상품 거래로 파산시킨 닉 리슨이 입힌 12억 달러보다도 큰 액수이다. 소시에테 제네랄 은행은 제롬이 다른 거래인의 명의를 도용해, 단독으로 선물상품 투자했다가 이 같은 손실을 냈다고 사고경위를 설명했으며, 제롬은 사표를 낸 상태이다. 다니엘 부통 최고 경영자도 회사를 그만두려고 했으나 이사회에서 반려되었다. 한편 소액주주를 포함한 100명이상의 주주들은 회사에 대해 소송을 할 예정이다.',\n",
       " '2007년 9월 26일, 껀터 대교 공사를 진행하던 도중에 지상 30m의 위치에 있던 교각이 붕괴되는 사고가 발생했다. 당시 250명의 노동자가 작업 중이었고, 다음날 27일에는 52명이 사망하고, 140명이 부상당했다고 보도되었다. 2008년 8월 11일에 사망자는 55명, 부상자는 79명으로 늘어났다. 10월 4일, 타이세이 건설 등의 JV를 비롯한 계약자들은 당장의 보상금으로 90억 동을 기부한다고 발표했다. (10억 동을 사망자에 대한 조위금, 부상자 위로금, 나머지 80억 동을 유족의 유아 70명이 18세가 될 때까지 양육비를 지급하기 위한 기금으로 조성) 이 프로젝트에 컨설턴트로 참여했던 니혼 코에이(日本工營)의 엔지니어는 2007년 6월 프로젝트 책임자에게 지보공 계통이 안전 계수를 채우지 못해 작업 조건이 매우 위험하다는 경고문을 보냈다. 다른 엔지니어도 2007년 1월 문서에서는 도움 버팀대 계통의 시공에 안전도를 확인을 위한 실험을 요구했다. 사고의 원인을 조사하기 위해 베트남 정부는 껀터 대교 붕괴 사고 조사 국가위원회를 설치했다. 컨설턴트의 경고 내용은 위원회 제2차 회의에서 거론되었고 시공을 맡은 JV 측은 그 후, 설계 검토와 보강 공사를 했다고 설명했다. 2008년 1월 8일 사고 조사 국가위원회는 응우옌 떤중 총리 붕괴 사고의 조사 결과에 대해 보고를 했다. 이 시점에서 최종 결론을 내리지는 않았지만, 응웬 총리는 시공법의 안전을 확인하고 공사를 재개하기로 합의했다. 사고 조사 국가위원회는 2008년 7월 2일에 최종 보고서를 발표했다. 이 보고서는 사고의 원인은 가설 지주 버팀대 기초가 부등침하 한 것이며, 보통의 설계 시 예측이 어려웠다고 결론을 내렸다. 조사 보고서를 근거로 베트남 관련 당국이 사고 책임 소재에 대해 조사와 검토를 했다. 이 최종 보고서를 받아 공사는 2008년 8월에 재개되었다.',\n",
       " '2016년 8월 26일, 하베스트를 인수하여 국고 수천억원을 낭비해 특정경제범죄 가중처벌법상 배임죄 혐의로 재판에 넘겨진 강영원(65) 전 한국석유공사 사장이 1심에 이어 항소심에서도 무죄를 선고받았다. 서울고법 형사8부(이광만 부장판사)는 배임죄의 고의가 없으며, 하베스트 인수로 석유공사에 손실이 생긴 것이 없으며, 유사사례를 살펴보니 인수가가 높지 않다고 판단했다. 검찰은 강력하게 반발했다. 1심과 2심은 세간의 하베스트 맹비난이 다 근거없다고 판단했다. 만약 검찰과는 정반대인 법원과 석유공사의 판단이 맞다면, 한국이 인수한 하베스트를 거의 공짜로 외국 정부가 빼앗아 가려는 시도로 해석할 수 있다.',\n",
       " '서울중앙지법 형사합의29부(천대엽 부장판사)는 2014년 1월 17일 업무상 과실치사 및 산업안전보건법 위반 혐의로 구속기소된 사건당시 하도급사 현장소장 권모(44)씨에게 징역 2년을 선고했다. 재판부는 \"권씨는 범람하는 물을 막으려고 설치한 차수막의 성능이 좋지 않고 사고 당일 안전을 위한 추가 조치가 필요하다는 사실을 알고 있었다\"며 \"(그런데도) 수몰 우려가 있는 현장에 근로자를 투입했다\"고 지적하며 \"이 사고는 안전불감증으로 일어난 인재\"라며 \"책임에 상응하는 형이 불가피하다\"고 양형 이유를 밝혔다. 권씨와 같은 혐의로 재판에 넘겨진 시공사 현장소장 박모(48)씨에게는 금고 2년에 집행유예 3년이, 책임감리관 이모(49)씨에게는 금고 1년6월에 집행유예 2년이 각각 선고됐다. 함께 재판에 넘겨진 서울시 상수도관리본부 공사관리관 이모(53)씨에게는 \"공사 현장의 안전에 대한 구체적 사안을 실질적으로 감독할 책임은 없다\"며 무죄가 선고되었다.',\n",
       " \"2008년에는 부적절한 대부영업이 드러난 산와 파이낸스와 다케후지에 대해 각자 일부 영업소 업무정지와 업무개선을 명령한 적이 있다. 대한민국에 '산와머니'라는 명칭으로 진출해 있는 산와 파이낸스의 경우 일부 지점에서 악질적인 채권추심행위가 발각됐고, 다케후지의 경우 채무자와의 접촉 내용 등이 제대로 기록되지 않은 것을 지적했다. 지난 해에도 금융청은 산와 파이낸스가 채무자의 친척들의 집에 빈번하게 방문해 압력을 가한 행위를 발각해 전체 지점 영업을 일시 정지시킨 바 있다. 그러나 이 같은 행위가 개선되지 않은 점포에 대해 이번에 업무 정지 명령을 내리게 된 것이다. 다케후지는 지난 2003년과 2004년에도 일시적인 업무정지 명령을 받은 적이 있는데, 이번에 조치가 강하지 않았던 것은 불법적 행위가 재발되지 않도록 내부적인 조사와 조치가 이루어진 것을 참작한 것이다.\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_p_retrieval_result[query[0]][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = load_from_disk(\"../data/test_dataset/validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question'],\n",
       "    num_rows: 600\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n",
      "[[1], [2]]\n"
     ]
    }
   ],
   "source": [
    "temp = {'a':[1],'b':[2]}\n",
    "\n",
    "print(list(temp.keys()))\n",
    "print(list(temp.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/dense_train.bin', \"rb\") as file:\n",
    "    dense_train_retrieval = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_dataset[''])\n",
    "dense_train_retrieval[query[0]][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [03:14<00:00, 20.30it/s]\n"
     ]
    }
   ],
   "source": [
    "new_context = []\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    train_context = train_dataset['context'][i]\n",
    "    sim_context = dense_train_retrieval[query[i]] # context list\n",
    "    cnt = 4\n",
    "    sim_context_idx = 0\n",
    "    sim_top_k = [train_context] # 정답 context를 제외한 top_k\n",
    "    # add_context = ' '.join(sim_context)\n",
    "    # sim_top_k.append(add_context)\n",
    "    # new_context.append(' '.join(sim_top_k))\n",
    "    while cnt != 0:\n",
    "        if train_context != sim_context[sim_context_idx]:\n",
    "            sim_top_k.append(sim_context[sim_context_idx])\n",
    "            cnt -= 1\n",
    "        sim_context_idx += 1\n",
    "    add_sim_context = ' '.join(sim_top_k)\n",
    "    new_context.append(add_sim_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dataset.to_pandas()\n",
    "train_df['context'] = new_context\n",
    "new_train_dataset = Dataset.from_pandas(train_df)\n",
    "new_train_dataset.save_to_disk('/opt/ml/data/train_dataset/new_train_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/opt/ml/data/dense_query_wiki_retrieval.bin', \"rb\") as file:\n",
    "#     pickle.dump(dense_p_retrieval_result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dataset.to_pandas()\n",
    "train_df['context'] = new_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_origin_df = train_dataset.to_pandas()\n",
    "# all_train = pd.concat([train_df, train_negative_df])\n",
    "# all_train.reset_index(drop=True)\n",
    "# all_train = all_train.drop(['__index_level_0__'],axis=1)\n",
    "# new_train_dataset = Dataset.from_pandas(all_train)\n",
    "# new_train_dataset.save_to_disk('/opt/ml/data/train_dataset/new_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "train_dataset = load_from_disk(\"/opt/ml/data/train_dataset/validation/\")\n",
    "query = train_dataset['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 15/15 [00:02<00:00,  5.84it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_batch_size = 16\n",
    "train_q_seqs = tokenizer(\n",
    "    query,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "query_dataset = TensorDataset(\n",
    "    train_q_seqs[\"input_ids\"],\n",
    "    train_q_seqs[\"attention_mask\"],\n",
    "    train_q_seqs[\"token_type_ids\"]\n",
    ")\n",
    "\n",
    "query_sampler = SequentialSampler(query_dataset)\n",
    "query_dataloader = DataLoader(\n",
    "    query_dataset,\n",
    "    sampler=query_sampler,\n",
    "    batch_size=eval_batch_size\n",
    ")\n",
    "\n",
    "q_embs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "        query_dataloader,\n",
    "        desc=\"Iteration\",\n",
    "        position=0,\n",
    "        leave=True\n",
    "    )\n",
    "    q_encoder.eval()\n",
    "\n",
    "    for _, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "        q_inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"token_type_ids\": batch[2]\n",
    "        }\n",
    "        \n",
    "        outputs = q_encoder(**q_inputs).to(\"cpu\").numpy()\n",
    "        q_embs.extend(outputs)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3340, 768)\n",
      "(240, 768)\n"
     ]
    }
   ],
   "source": [
    "p_embs = np.array(p_embs)\n",
    "q_embs = np.array(q_embs)\n",
    "\n",
    "print(p_embs.shape)\n",
    "print(q_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    p_embs_cuda = torch.Tensor(p_embs).to('cuda')\n",
    "    q_embs_cuda = torch.Tensor(q_embs).to('cuda')\n",
    "\n",
    "dot_prod_scores = torch.matmul(q_embs_cuda, torch.transpose(p_embs_cuda, 0, 1))\n",
    "rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 3473.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dense_p_retrieval_result = {}\n",
    "idx = 0\n",
    "for i in tqdm(range(len(query))):\n",
    "    p_list = []\n",
    "    q = query[i]\n",
    "    for j in range(10):\n",
    "        p_list.append(train_corpus[rank[idx][j]])\n",
    "    dense_p_retrieval_result[q] = p_list\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 304.76it/s]\n"
     ]
    }
   ],
   "source": [
    "new_context = []\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    train_context = train_dataset['context'][i]\n",
    "    sim_context = dense_p_retrieval_result[query[i]] # context list\n",
    "    cnt = 4\n",
    "    sim_context_idx = 0\n",
    "    sim_top_k = [train_context] # 정답 context를 제외한 top_k\n",
    "    # add_context = ' '.join(sim_context)\n",
    "    # sim_top_k.append(add_context)\n",
    "    # new_context.append(' '.join(sim_top_k))\n",
    "    while cnt != 0:\n",
    "        if train_context != sim_context[sim_context_idx]:\n",
    "            sim_top_k.append(sim_context[sim_context_idx])\n",
    "            cnt -= 1\n",
    "        sim_context_idx += 1\n",
    "    add_sim_context = ' '.join(sim_top_k)\n",
    "    new_context.append(add_sim_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dataset.to_pandas()\n",
    "train_df['context'] = new_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음으로 부실 경영인에 대한 보상 선고를 받은 회사는?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법시험에 합격하여 판사로 임용되었고 대법원 재판연구관, 수원지법 부장판사, 사법연수원 교수, 특허법원 부장판사 등을 거쳐 능력을 인정받았다. 2003년 최종영 대법원장의 지명으로 헌법재판소 재판관을 역임하였다.\\\\n\\\\n경제민주화위원회(위원장 장하성이 소액주주들을 대표해 한보철강 부실대출에 책임이 있는 이철수 전 제일은행장 등 임원 4명을 상대로 제기한 손해배상청구소송에서 서울지방법원 민사합의17부는 1998년 7월 24일에 \"한보철강에 부실 대출하여 은행에 막대한 손해를 끼친 점이 인정된다\"며 \"원고가 배상을 청구한 400억원 전액을 은행에 배상하라\"고 하면서 부실 경영인에 대한 최초의 배상 판결을 했다. \\\\n\\\\n2004년 10월 신행정수도의건설을위한특별조치법 위헌 확인 소송에서 9인의 재판관 중 유일하게 각하 견해를 내었다. 소수의견에서 전효숙 재판관은 다수견해의 문제점을 지적하면서 관습헌법 법리를 부정하였다. 전효숙 재판관은 서울대학교 근대법학교육 백주년 기념관에서 열린 강연에서, 국회가 고도의 정치적인 사안을 정치로 풀기보다는 헌법재판소에 무조건 맡겨서 해결하려는 자세는 헌법재판소에게 부담스럽다며 소회를 밝힌 바 있다. 호르스트 제호퍼 주총리 밑에서 재무장관을 지냈으며, 주를 대변하는 연방 상원의원으로서 상원 재무위원회 소속이었다.\\\\n\\\\n재무장관 시절 유럽 연합 집행위원회의 일괄 지원을 받고자 부실 주 지원 대출은행인 바이에른LB의 재건을 감독하기도 했다. 2014년에는 바이에른LB를 압박하여 헝가리 측에 MKB 단위를 매각함으로서 20여년 간 20억 유로의 손실을 초래한 부실투자를 종식시키기도 했다. 2015년에는 한스 외르크 셸링 오스트리아 외무장관과 협상을 타결하여 하이포 알페아드리아뱅크 인터내셔널(케른텐주 지역 은행)의 붕괴에서 시작된 양측 정부의 법적 분쟁을 끝냈다. 양해 각서에 따르면 오스트리아는 바이에른주에 12억 3천만 유로를 지불하며, 모든 관련 소송은 취하되었다. \\\\n\\\\n2012년 죄더는 제호퍼 당시 주총리와 함께 연방헌법법원에 소송을 제기하여 바이에른처럼 부유한 주가 전국의 부실경제 구제 차원에서 재정이전을 하도록 하는 독일 시스템 점검을 요구했다. 죄더의 제안에 따라 바이에른주 정부는 독일 최초로 폭스바겐을 상대로 배출가스 시험 사기 사건 관련 소송을 제기해 손해배상을 요구한 주가 되었다. 이 시기 죄더는 해당 스캔들로 인해 70만 유로에 달하는 공무원 연금기금 손실을 입었다고 밝혔다. \\\\n\\\\n2017년 총선 결과 기사련이 참패하면서 제호퍼는 대표직 사퇴 압력을 받게 되었고, 이에 그는 당대표직에서 물러나지는 않는 대신 바이에른주 총리직은 죄더에게 인계하겠다고 밝혔다. 1943년에 경상북도 칠곡군에서 출생하였다. 1970년에 사진가로 입문하여 초기에는 인간의 삶을 다룬 다큐멘터리 사진을 촬영했고, 1989년에 백두산에서 사진 촬영을 하면서 산 사진에 뛰어들어 6개월 동안 산 속에 살면서 작업을 해왔다. 그리고 산 사진 촬영을 통해 터득한 모습으로 높고 험준한 산에서 모습을 드러낸 바 없는 걸작 소나무를 찾아내어 사진에 담고 있었다.\\\\n\\\\n그러나 2011년~2013년 사이에 경상북도 울진군에 소재한 산림유전자원보호구역에서 사진을 촬영하던 도중, 사진 구도에 방해된다는 이유로 200년이 넘은 금강송과 그 외의 나무들을 무단으로 벌목한 것에 대해 논란이 되었다. 이 사건이 언론에 보도되면서 많은 사람들이 분노를 겪였으며, 그는 형사에게 기소되면서 500만원의 벌금형을 선고받았다. 그와 동시에 한국사진작가협회에서 영구제명을 당했으며, 대다수의 환경단체와 사진작가단체에서 사진전 개최에 반대의사는 물론 보이콧까지 일으켰다.\\\\n\\\\n이후 본래 예술의 전당에서 개최하려고 했던 그의 사진전을 미술과 비평에 취소되었다는 소식이 전해졌으나, 이를 상대로 전시회 금지 취소 요청을 하면서 가처분 신청을 냈고, 4월 6일에 서울중앙지법이 이를 받아들여 전시회를 열었다. 이 소식을 들은 환경 단체, 사진 작가 단체, SNS 이용자들이 또 다시 분노를 일으켰으며, 예술의 전당 디자인미술관 정문에서 현역 사진작가들이 릴레이 1인 시위를 했을 정도다. 일본은 한국과 마찬가지로 형사소송법상의 기소편의주의에 의해 사건에 대한 불기소처분을 검찰관(검사)의 재량에 따라 할 수 있다. 하지만 고소한 사람이 이에 불복하는 경우 민간인으로 이루어진 검찰심사회에 불기소 처분이 타당한지에 대한 심사를 요청할 수 있으며, 이는 민의를 이용한 기소독점주의에 대한 하나의 견제 방편이다.\\\\n\\\\n일본 검찰심사회에서는 2008년까지 약 15만건의 불기소 사건들을 심사해 그 중 11.3%에 대해 \"불기소 부당\" 또는 \"기소 상당\"의 의견으로 의결했고, 검찰은 이 중 1400여건을 기소해 징역 10년형의 중형에 처해진 경우도 있다. 검찰심사회는 미나마타병 사건, 일본항공 350편 하네다해 추락 사건 , 일본항공 123편 점보제트기 추락 사건, 에이즈 혈우병 치료제 사건 , 토요하마 터널 암반 추락 사건 , 유키지루시 집단 식중독 사건 , 아카시 불꽃놀이 보도교 사고 및 오자와 이치로 일본 민주당 간사장의 기소 처분 등의 사회적 이목을 끈 사건들을 맡기도 했다.\\\\n\\\\n일본에서는 검찰심사원으로 연간 약 7,300명이 선발되며, 총 54만명이 심사원으로 일해본 경험이 있다. 현재 미국, 일본, 프랑스에서 도입중이다. 2005년에 포이즌 필을 도입한 일본에서는 분쟁을 통해 판례까지 등장하고 있다 113 대한민국의 경우, 기업들이 포이즌 필, 차등의결권주식 등을 포함한 새로운 경영권 방어 장치의 도입을 계속 요구하였 30 대한민국의 학계에서도 이미 많은 논의가 진행되어 왔다 113 코스닥 등록 창투사인 옵셔널벤처스코리아는 2001년 7월 대표이사가 임기 중 타의에 의하여 강제퇴임할 경우 50억원의 위로금을 지급해야 한다는 포이즌 필 조항을을 채택하하여 첨단 M&A 방어기법이냐, 건전한 M&A를 막는 독소조항이냐라는 논란을 불러일으켰다. 옵셔널벤처스코리아의 2대 주주인 광주은행이 소액주주들에게 의결권위임을 받아 임원퇴직금지급규정 변경안을 저지하려고 하였으나 실패하였다. 현재 법무부가 준비 중인 상법 개정안은 신주인수선택권이라는 명칭으로 포이즌 필을 도입하려고 한다. 이에 의하면 회사는 정관으로 주주에게 그가 가진 주식의 종류 및 수에 따라 미리 정한 가액으로 일정한 기간 내에 회사에 대하여 신주의 발행을 청구할 수 있는 권리를 부여할 수 있으며 이 권리가 신주인수선택권이다 114'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df['question'][0])\n",
    "train_df['context'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "new_train_dataset = Dataset.from_pandas(train_df)\n",
    "new_train_dataset.save_to_disk('/opt/ml/data/train_dataset/new_validation_v2')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_dataset['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [15:34<00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "new_reverse_context = []\n",
    "new_reverse_answer = []\n",
    "# len(train_dataset)\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    train_context = train_dataset['context'][i]\n",
    "    sim_context = dense_train_retrieval_result[query[i]] # context list\n",
    "\n",
    "\n",
    "    cnt = 1\n",
    "    sim_context_idx = 2\n",
    "    sim_top_k = [] # 정답 context를 제외한 top_k\n",
    "    temp_answer = {}\n",
    "\n",
    "    add_start_idx = 0\n",
    "    while cnt != 0:\n",
    "        if train_context != sim_context[sim_context_idx]:\n",
    "            sim_top_k.append(sim_context[sim_context_idx])\n",
    "            add_start_idx += len(sim_context[sim_context_idx]) + 1 # 공백까지 포함\n",
    "            cnt -= 1\n",
    "        sim_context_idx += 1\n",
    "    sim_top_k.append(train_context)\n",
    "    add_sim_context = ' '.join(sim_top_k)\n",
    "    # 시간 복잡도?\n",
    "    temp_answer['answer_start'] = [train_dataset['answers'][i]['answer_start'][0] + add_start_idx]\n",
    "    temp_answer['text'] = train_dataset['answers'][i]['text']\n",
    "    new_reverse_answer.append(temp_answer)\n",
    "    new_reverse_context.append(add_sim_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reverse_df = train_dataset.to_pandas()\n",
    "train_reverse_df['context'] = new_reverse_context\n",
    "train_reverse_df['answers'] = new_reverse_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'백'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reverse_df['context'][2][train_reverse_df['answers'][2]['answer_start'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [15:44<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "new_reverse_negative_context = []\n",
    "new_reverse_negative_answer = []\n",
    "# len(train_dataset)\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    train_context = train_dataset['context'][i]\n",
    "    sim_context = dense_train_retrieval_result[query[i]] # context list\n",
    "\n",
    "\n",
    "    cnt = 1\n",
    "    sim_context_idx = -2\n",
    "    sim_top_k = [] # 정답 context를 제외한 top_k\n",
    "    temp_answer = {}\n",
    "\n",
    "    add_start_idx = 0\n",
    "    while cnt != 0:\n",
    "        if train_context != sim_context[sim_context_idx]:\n",
    "            sim_top_k.append(sim_context[sim_context_idx])\n",
    "            add_start_idx += len(sim_context[sim_context_idx]) + 1 # 공백까지 포함\n",
    "            cnt -= 1\n",
    "        sim_context_idx -= 1\n",
    "    sim_top_k.append(train_context)\n",
    "    add_sim_context = ' '.join(sim_top_k)\n",
    "    # 시간 복잡도?\n",
    "    temp_answer['answer_start'] = [train_dataset['answers'][i]['answer_start'][0] + add_start_idx]\n",
    "    temp_answer['text'] = train_dataset['answers'][i]['text']\n",
    "    new_reverse_negative_answer.append(temp_answer)\n",
    "    new_reverse_negative_context.append(add_sim_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reverse_negative_df = train_dataset.to_pandas()\n",
    "train_reverse_negative_df['context'] = new_reverse_negative_context\n",
    "train_reverse_negative_df['answers'] = new_reverse_negative_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin_df = train_dataset.to_pandas()\n",
    "all_train = pd.concat([train_origin_df, train_df, train_negative_df,train_reverse_df,train_reverse_negative_df])\n",
    "all_train.reset_index(drop=True)\n",
    "all_train = all_train.drop(['__index_level_0__'],axis=1)\n",
    "new_train_dataset = Dataset.from_pandas(all_train)\n",
    "new_train_dataset.save_to_disk('/opt/ml/data/train_dataset/new_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.drop(['__index_level_0__'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_dataset = Dataset.from_pandas(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
