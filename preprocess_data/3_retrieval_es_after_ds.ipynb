{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from datasets import load_from_disk, Dataset\n",
    "from transformers import AutoTokenizer,BertTokenizerFast\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from retrieval_model import BertEncoder,RobertaEncoder\n",
    "from torch import nn\n",
    "from torch.utils.data import (DataLoader,TensorDataset, SequentialSampler)\n",
    "from tqdm import tqdm, trange\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/p_encoder\")\n",
    "q_encoder = BertEncoder.from_pretrained(\"/opt/ml/mrc-level2-nlp-08/retrieval/q_encoder\")\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "if torch.cuda.is_available():\n",
    "        p_encoder.cuda()\n",
    "        q_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wiki_context_id_pair.bin','rb') as f:\n",
    "    wiki_context_id = pickle.load(f)\n",
    "with open('/opt/ml/data/wiki_id_context_pair.bin','rb') as f:\n",
    "    wiki_id_context = pickle.load(f)\n",
    "# with open('/opt/ml/data/dense_embedding.bin','rb') as f:\n",
    "#     p_embs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_corpus = list(wiki_context_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_doc(q_encoder, p_encoder, query, context, elastic_score_dict,weight, k=100):\n",
    "    with torch.no_grad():\n",
    "        p_encoder.eval()\n",
    "        q_encoder.eval()\n",
    "\n",
    "        q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "        #q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "        q_emb = q_encoder(**q_seqs_val)\n",
    "\n",
    "        p_embs = []\n",
    "        p_seqs = tokenizer(context, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        dataset = TensorDataset(\n",
    "            p_seqs[\"input_ids\"],\n",
    "            p_seqs[\"attention_mask\"],\n",
    "            p_seqs[\"token_type_ids\"]\n",
    "        )\n",
    "        sampler = SequentialSampler(dataset)\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            sampler=sampler,\n",
    "            batch_size=100\n",
    "        )\n",
    "        for _, batch in enumerate(dataloader):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "            p_inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2]\n",
    "            }\n",
    "            \n",
    "            #outputs = p_encoder(**p_inputs).to(\"cpu\").numpy()\n",
    "            outputs = p_encoder(**p_inputs)\n",
    "            p_embs.extend(outputs.unsqueeze(0))\n",
    "    p_embs = torch.cat(p_embs).cuda()\n",
    "    q_emb = q_emb.cuda()\n",
    "    #print(p_embs.size())\n",
    "    #p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "    \n",
    "    dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "    elastic_score = torch.Tensor([elastic_score_dict[query]]).cuda()\n",
    "\n",
    "    weight_score = weight * dot_prod_scores\n",
    "\n",
    "    temp_score = elastic_score + weight_score\n",
    "\n",
    "    #rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "    rank = torch.argsort(temp_score, dim=1, descending=True).squeeze()\n",
    "    #print(rank)\n",
    "\n",
    "    return_top_id = []\n",
    "    for i in range(k):\n",
    "        return_top_id.append(wiki_context_id[context[rank[i]]])\n",
    "    \n",
    "    return dot_prod_scores.squeeze(), return_top_id #,rank[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/elastic_valid_200.bin','rb') as f:\n",
    "    elastic_valid = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_valid_score_200.bin','rb') as f:\n",
    "    elastic_valid_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = list(elastic_valid.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [08:15<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "for i in tqdm(range(len(querys))):\n",
    "    q = querys[i]\n",
    "    context = []\n",
    "    for doc_id in elastic_valid[querys[i]]:\n",
    "        context.append(wiki_id_context[doc_id])\n",
    "    _, re_rank = get_relevant_doc(q_encoder,p_encoder,q,context,elastic_valid_score,1.1,100)\n",
    "    hybrid[querys[i]] = re_rank\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_valid_retrieval_1.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/opt/ml/data/elastic_new_train_500.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-98bfe109bd13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/opt/ml/data/elastic_new_train_500.bin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0melastic_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/opt/ml/data/elastic_new_train_score_500.bin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0melastic_train_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/opt/ml/data/elastic_new_train_500.bin'"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/data/elastic_new_train_500.bin','rb') as f:\n",
    "    elastic_train = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_new_train_score_500.bin','rb') as f:\n",
    "    elastic_train_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [2:20:41<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "querys = list(elastic_train.keys())\n",
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "for i in tqdm(range(len(querys))):\n",
    "    _, re_rank = get_relevant_doc(q_encoder,p_encoder,querys[i],elastic_train[querys[i]],elastic_train_score)\n",
    "    hybrid[querys[i]] = re_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_train_retrieval.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/elastic_test_200.bin','rb') as f:\n",
    "    elastic_test = pickle.load(f)\n",
    "with open('/opt/ml/data/elastic_test_score_200.bin','rb') as f:\n",
    "    elastic_test_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [20:42<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "querys = list(elastic_test.keys())\n",
    "hybrid = {}\n",
    "# range(len(querys))\n",
    "for i in tqdm(range(len(querys))):\n",
    "    q = querys[i]\n",
    "    context = []\n",
    "    for doc_id in elastic_test[querys[i]]:\n",
    "        context.append(wiki_id_context[doc_id])\n",
    "    _, re_rank = get_relevant_doc(q_encoder,p_encoder,q,context,elastic_test_score,1.1,100)\n",
    "    hybrid[querys[i]] = re_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/data/hybrid_test_retrieval.bin\", \"wb\") as file:\n",
    "    pickle.dump(hybrid,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15241,\n",
       " 8271,\n",
       " 42254,\n",
       " 21683,\n",
       " 8270,\n",
       " 6496,\n",
       " 10097,\n",
       " 32440,\n",
       " 43278,\n",
       " 10591,\n",
       " 12636,\n",
       " 25852,\n",
       " 20984,\n",
       " 43284,\n",
       " 15858,\n",
       " 14809,\n",
       " 21334,\n",
       " 16188,\n",
       " 37806,\n",
       " 10075,\n",
       " 24228,\n",
       " 16035,\n",
       " 19928,\n",
       " 8197,\n",
       " 10076,\n",
       " 25115,\n",
       " 46184,\n",
       " 7582,\n",
       " 22848,\n",
       " 29937,\n",
       " 20920,\n",
       " 51485,\n",
       " 41543,\n",
       " 14528,\n",
       " 33622,\n",
       " 16517,\n",
       " 35500,\n",
       " 25213,\n",
       " 5740,\n",
       " 28423,\n",
       " 8391,\n",
       " 19021,\n",
       " 45424,\n",
       " 55072,\n",
       " 6120,\n",
       " 18223,\n",
       " 36354,\n",
       " 55705,\n",
       " 39891,\n",
       " 35557,\n",
       " 30519,\n",
       " 14532,\n",
       " 11403,\n",
       " 5230,\n",
       " 19641,\n",
       " 48253,\n",
       " 37423,\n",
       " 18622,\n",
       " 23642,\n",
       " 29617,\n",
       " 8095,\n",
       " 7322,\n",
       " 41513,\n",
       " 39187,\n",
       " 27584,\n",
       " 11718,\n",
       " 18698,\n",
       " 11523,\n",
       " 29045,\n",
       " 40206,\n",
       " 20347,\n",
       " 15301,\n",
       " 23681,\n",
       " 58569,\n",
       " 49073,\n",
       " 31351,\n",
       " 8806,\n",
       " 48331,\n",
       " 22911,\n",
       " 9038,\n",
       " 7623,\n",
       " 18282,\n",
       " 19804,\n",
       " 9250,\n",
       " 12648,\n",
       " 28447,\n",
       " 26399,\n",
       " 31498,\n",
       " 39116,\n",
       " 44839,\n",
       " 29298,\n",
       " 8466,\n",
       " 35562,\n",
       " 47877,\n",
       " 54491,\n",
       " 43451,\n",
       " 17853,\n",
       " 36355,\n",
       " 18908,\n",
       " 16085]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid[querys[599]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부피와 무게감을 나타낸 얼굴이나 짧은 목 등을 통해 알 수 있는 불상의 축조 시기는?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'경상북도 예천군 예천읍 동본동 3층석탑과 함께 전해오는 통일신라 후기의 불상으로 하나의 돌에 새겨진 전체 높이 3.46m의 거대한 석조불상이다. 머리에는 작은 소라 모양의 머리칼을 붙여 놓았으며, 정수리 부근에는 상투 모양의 머리(육계)가 큼직하게 표현되었다. 원만한 얼굴에는 길다란 눈, 짧은 코, 적당한 입이 적절하게 표현되어 부드러운 곡선의 얼굴과 함께 자비롭고 온화한 미소를 실감나게 나타내고 있다. 큰 얼굴에 비하여 작아진 상체는 굵고 짧은 목과 좁은 어깨, 짧은 팔 등이 평판적인 가슴과 함께 움츠린 듯하여 다소 위축된 느낌을 준다. 오른팔은 옆으로 내려 몸에 붙인 채 옷자락을 살짝 잡고 있으며, 왼손은 앞으로 들어 새끼 손가락을 제외한 손가락을 안으로 굽히고 있다. 양 어깨를 감싸고 입은 옷은 허벅지에서 Y자형으로 갈라지고 양 다리에서는 타원형의 주름을 만들면서 흐른다. 둔중하고 도식화된 이러한 형태의 옷주름 표현은 8세기 이후의 불상에서 흔히 볼 수 있는 모습으로 불상이 만들어진 연대를 짐작할 수 있게 해준다. 양 다리에서 있는 긴 타원형의 옷주름, 부피감 없는 둔중한 신체, 그러면서도 아직 경직화되지는 않은 얼굴 모습 등을 고려할 때 통일신라 불상양식을 계승하면서 고려시대로 넘어가는 과도기적인 작품으로 보인다.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 250\n",
    "print(querys[num])\n",
    "hybrid[querys[num]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_relevant_doc_with_embs(q_encoder, p_embs, query, elastic_ids, elastic_score_dict):\n",
    "#     with torch.no_grad():\n",
    "#         q_encoder.eval()\n",
    "\n",
    "#         q_seqs_val = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "#         q_emb = q_encoder(**q_seqs_val).to('cuda')  #(num_query, emb_dim)\n",
    "\n",
    "#     elastic_score = elastic_score_dict[query]\n",
    "#     dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "#     rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "#     #print(dot_prod_scores.size())\n",
    "    \n",
    "#     elastic_context = []\n",
    "\n",
    "#     for e_ids in elastic_ids:\n",
    "#         elastic_context.append(wiki_id_context[e_ids])\n",
    "\n",
    "\n",
    "#     elastic_id_score = {k : v for k, v in zip(elastic_context, elastic_score)}\n",
    "\n",
    "#     es_id_score = {}\n",
    "#     dense_id_score = {}\n",
    "#     idx = 0\n",
    "#     cnt = len(elastic_ids)\n",
    "    \n",
    "#     #print(elastic_context)\n",
    "#     #print(cnt)\n",
    "#     while cnt != 0:\n",
    "#         try:\n",
    "#             if wiki_corpus[rank[idx]] in elastic_context:\n",
    "\n",
    "#                 dense_id_score[wiki_corpus[rank[idx]]] = dot_prod_scores[0][idx].item()\n",
    "#                 es_id_score[wiki_corpus[rank[idx]]] = elastic_id_score[wiki_corpus[rank[idx]]]\n",
    "#                 cnt -= 1\n",
    "#                 #print(cnt)\n",
    "#             idx += 1\n",
    "#         except:\n",
    "#             print(cnt)\n",
    "#             break\n",
    "    \n",
    "\n",
    "    \n",
    "#     return es_id_score, dense_id_score#, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid = {}\n",
    "# for i in tqdm(range(len(querys))):\n",
    "#     q = querys[i]\n",
    "#     context = []\n",
    "#     es,ds = get_relevant_doc_with_embs(q_encoder,p_embs_cuda,q,elastic_valid[q],elastic_valid_score)\n",
    "#     top_k_id_score = []\n",
    "#     for doc_id in list(es.keys()):\n",
    "#         top_k_id_score.append([doc_id, es[doc_id] + 1.1 *ds[doc_id]])\n",
    "\n",
    "#     top_k_ids = sorted(top_k_id_score,key=lambda x: x[1],reverse=True)\n",
    "\n",
    "#     texts = []\n",
    "#     for text in top_k_ids:\n",
    "#         texts.append(wiki_context_id[text[0]])\n",
    "#     hybrid[q] = texts"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
